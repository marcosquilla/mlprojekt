{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from typing import Tuple, List, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from pyproj import Geod\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "import folium\n",
    "import folium.plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs84_geod = Geod(ellps='WGS84') # Distance will be measured in meters on this ellipsoid - more accurate than a spherical method\n",
    "def distance(lat1,lon1,lat2,lon2):\n",
    "    _,_,dist = wgs84_geod.inv(lon1,lat1,lon2,lat2) # Yes, this order is correct\n",
    "    return dist\n",
    "\n",
    "def coords_to_areas(target: pd.Series) -> pd.Series: # Calculate to which area an opening's coordinates (target) \"belong to\"\n",
    "    # Following 3 lines needed to have a Series of the same length as area_centers with target as value\n",
    "    dist = deepcopy(area_grid) # Without deepcopy area_centers is modified in the next 2 lines\n",
    "    dist['TGPS_Latitude'] = target['GPS_Latitude']\n",
    "    dist['TGPS_Longitude'] = target['GPS_Longitude']\n",
    "    \n",
    "    dist = distance(dist['GPS_Latitude'], dist['GPS_Longitude'], dist['TGPS_Latitude'], dist['TGPS_Longitude'])\n",
    "    return pd.Series(1 - dist / sum(dist)) # Percentage of how much an opening belongs to each area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental = pd.read_csv(Path.cwd().parent / 'data' / 'processed' / 'rental.csv', low_memory=False)\n",
    "openings = pd.read_csv(Path.cwd().parent / 'data' / 'processed' / 'openings.csv')\n",
    "virtual_area_centers = pd.read_csv(Path.cwd().parent / 'data' / 'processed' / 'areas.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area centers based on current areas\n",
    "area_centers = rental.groupby('Start_Zone_Name').mean()[['Start_GPS_Latitude','Start_GPS_Longitude']]\n",
    "area_centers.rename(columns={\n",
    "    'Start_GPS_Latitude': 'GPS_Latitude', \n",
    "    'Start_GPS_Longitude': 'GPS_Longitude'}, inplace=True)\n",
    "area_centers.index.names = ['Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental['Start_Datetime_Local'] = pd.to_datetime(rental['Start_Datetime_Local'], format='%Y-%m-%d %H:%M')\n",
    "rental['End_Datetime_Local'] = pd.to_datetime(rental['End_Datetime_Local'], format='%Y-%m-%d %H:%M')\n",
    "rental = pd.get_dummies(rental, columns=['Vehicle_Engine_Type'], drop_first=True)\n",
    "rental = pd.get_dummies(rental, columns=['Vehicle_Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openings['Created_Datetime_Local'] = pd.to_datetime(openings['Created_Datetime_Local'], format='%Y-%m-%d %H:%M')\n",
    "openings = pd.get_dummies(openings, columns=['Platform'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = max(rental['Start_Datetime_Local'].min(), openings['Created_Datetime_Local'].min())\n",
    "time_end = min(rental['End_Datetime_Local'].max(), openings['Created_Datetime_Local'].max())\n",
    "print('Time limits:', time_start, 'to', time_end)\n",
    "total_time = time_end-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    timepoint = time_start + timedelta(seconds=total_time.total_seconds()*random.uniform(0,1))\n",
    "    #filtered_rentals = rental[rental['End_Datetime_Local'] <= timepoint].drop('Revenue_Net', axis=1)\n",
    "    #filtered_rentals = filtered_rentals.sort_values(by='End_Datetime_Local').drop_duplicates(subset='Vehicle_Number_Plate', keep='last') # Keep the last location\n",
    "    current_trips = rental[(rental['Start_Datetime_Local'] <= timepoint) & (rental['End_Datetime_Local'] > timepoint) & (rental['Servicedrive_YN']==1)] # Cars in use\n",
    "    ratio.append(len(current_trips))\n",
    "\n",
    "bins = np.arange(0, 10, 1) # fixed bin size\n",
    "plt.xlim([0, 10])\n",
    "plt.hist(ratio, bins=bins, density=True)\n",
    "plt.title('Histogram of cars being relocated at random times')\n",
    "plt.xlabel('Cars being relocated')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    timepoint = time_start + timedelta(seconds=total_time.total_seconds()*random.uniform(0,1))\n",
    "    #filtered_rentals = rental[rental['End_Datetime_Local'] <= timepoint].drop('Revenue_Net', axis=1)\n",
    "    #filtered_rentals = filtered_rentals.sort_values(by='End_Datetime_Local').drop_duplicates(subset='Vehicle_Number_Plate', keep='last') # Keep the last location\n",
    "    current_trips = rental[(rental['Start_Datetime_Local'] <= timepoint) & (rental['End_Datetime_Local'] > timepoint) & (rental['Servicedrive_YN']==0)] # Cars in use\n",
    "    ratio.append(len(current_trips))\n",
    "\n",
    "bins = np.arange(0, 200, 1) # fixed bin size\n",
    "plt.xlim([0, 200])\n",
    "plt.hist(ratio, bins=bins, density=True)\n",
    "plt.title('Histogram of cars in random times')\n",
    "plt.xlabel('Cars in use')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental['After_reloc'] = rental.groupby('Vehicle_Number_Plate')['Servicedrive_YN'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0)]['Revenue_Net'], bins=range(0,200,10), density=True, alpha=0.5, label='All revenues')\n",
    "plt.hist(rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0) & (rental['After_reloc']==1)]['Revenue_Net'], bins=range(0,200,10), density=True, alpha=0.5, label='Revenues after relocation')\n",
    "plt.hist(rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0) & (rental['After_reloc']==0)]['Revenue_Net'], bins=range(0,200,10), density=True, alpha=0.5, label='Revenues without relocation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('Mean total:', '{:2.2f}'.format(rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0)]['Revenue_Net'].mean()))\n",
    "print('Mean after relocation:', '{:2.2f}'.format(rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0) & (rental['After_reloc']==1)]['Revenue_Net'].mean()))\n",
    "print('Mean without relocation:', '{:2.2f}'.format(rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0) & (rental['After_reloc']==0)]['Revenue_Net'].mean()))\n",
    "print('Increase:', '{:2.2%}'.format(rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0) & (rental['After_reloc']==1)]['Revenue_Net'].mean()/rental[(rental['Servicedrive_YN']==0) & (rental['Revenue_Net']!=0)]['Revenue_Net'].mean()-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of rentals per zone')\n",
    "rental.groupby('Start_Zone_Name')['Vehicle_Number_Plate'].count().sort_values(ascending=False)/len(rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of rentals per zone')\n",
    "rental.groupby('Virtual_Start_Zone_Name')['Vehicle_Number_Plate'].count().sort_values(ascending=False)/len(rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=range(len(virtual_area_centers)), height=rental.groupby('Virtual_Start_Zone_Name')['Vehicle_Number_Plate'].count().sort_values(ascending=False).values/len(rental), alpha=0.7, label='Virtual', width=1)\n",
    "plt.bar(x=range(len(area_centers)), height=rental.groupby('Start_Zone_Name')['Vehicle_Number_Plate'].count().sort_values(ascending=False).values/len(rental), alpha=0.7, label='Original', width=1)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution of rentals unassigned to areas')\n",
    "start_map_heat = folium.Map([55.6785706133019, 12.594427257404426], zoom_start=12, tiles='Stamen Toner')\n",
    "folium.plugins.HeatMap(rental[rental['Start_Zone_Name']=='-'].loc[:,['Start_GPS_Latitude', 'Start_GPS_Longitude']], name=None, min_opacity=0.5, max_zoom=18, radius=10,\n",
    "blur=8, gradient=None, overlay=True, control=True, show=True).add_to(start_map_heat)\n",
    "display(start_map_heat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Areas vs. virtual areas')\n",
    "start_map = folium.Map([55.6785706133019, 12.594427257404426], zoom_start=12, tiles='Stamen Toner')\n",
    "for name, row in area_centers.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        radius=5,\n",
    "        location=[row['GPS_Latitude'], row['GPS_Longitude']],\n",
    "        color=\"crimson\",\n",
    "        tooltip=name,\n",
    "        fill=False,\n",
    "    ).add_to(start_map)\n",
    "for name, row in virtual_area_centers.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        radius=5,\n",
    "        location=[row['GPS_Latitude'], row['GPS_Longitude']],\n",
    "        color=\"blue\",\n",
    "        tooltip=name, \n",
    "        fill=True\n",
    "    ).add_to(start_map)\n",
    "display(start_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rent_locs(i, fmap, quatity:int=100, colour='crimson'):\n",
    "    area = virtual_area_centers.index[i]\n",
    "    rent_locs = rental[rental['Virtual_Start_Zone_Name']==area].loc[:,['Start_GPS_Latitude', 'Start_GPS_Longitude']].iloc[:quatity]\n",
    "    for _, row in rent_locs.iterrows():\n",
    "        folium.Circle(\n",
    "            radius=10,\n",
    "            location=[row['Start_GPS_Latitude'], row['Start_GPS_Longitude']],\n",
    "            color=colour,\n",
    "            fill=False,\n",
    "        ).add_to(start_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_map = folium.Map([55.6785706133019, 12.594427257404426], zoom_start=12, tiles='Stamen Toner')\n",
    "\n",
    "plot_rent_locs(186, start_map, colour='red')\n",
    "plot_rent_locs(310, start_map, colour='green')\n",
    "plot_rent_locs(59, start_map, colour='yellow')\n",
    "plot_rent_locs(227, start_map, colour='purple')\n",
    "\n",
    "for idx, row in virtual_area_centers.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['GPS_Latitude'], row['GPS_Longitude']],\n",
    "        color=\"blue\",\n",
    "        tooltip=idx, \n",
    "        fill=True\n",
    "    ).add_to(start_map)\n",
    "\n",
    "display(start_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(timepoint:datetime, window:timedelta=timedelta(hours=1)):\n",
    "        a = rental[(rental['Servicedrive_YN']==1) &\n",
    "                        (rental['Start_Datetime_Local'] >= timepoint-window) &\n",
    "                        (rental['End_Datetime_Local'] < timepoint)]\n",
    "        all_vehicles = rental.columns[rental.columns.str.contains('Vehicle_Model')] # Get name of vehicles\n",
    "        a = a[a['Start_Zone_Name'] != a['End_Zone_Name']]\n",
    "        a = a.loc[:, [*all_vehicles, 'Start_Zone_Name', 'End_Zone_Name', 'Servicedrive_YN']]\n",
    "        a = pd.melt(a, id_vars=['Start_Zone_Name', 'End_Zone_Name'], value_vars=[*all_vehicles])\n",
    "        a.rename(columns={'variable': 'Vehicle_Model'}, inplace=True)\n",
    "        #return a\n",
    "        return a.groupby(['Vehicle_Model', 'Start_Zone_Name', 'End_Zone_Name']).sum().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions(timepoint=datetime(2020, 6, 12, 12, 0, 0), window=timedelta(hours=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns time openings in the last time window at any datetime. Softmax preferred False to get absolute values (an increase in demand everywhere -> softmax is the same)\n",
    "def demand(timepoint:datetime, window:timedelta=timedelta(hours=1), app_openings:pd.DataFrame=openings, detail:bool=False) -> pd.DataFrame:\n",
    "    demand_df = deepcopy(app_openings[(app_openings['Created_Datetime_Local'] > timepoint-window) &\n",
    "                             (app_openings['Created_Datetime_Local'] <= timepoint)])\n",
    "    demand_df[area_grid.index.values] = 0 # Create columns with area names\n",
    "    demand_df[area_grid.index.values] = demand_df.apply(coords_to_areas, axis=1) # Apply function to all openings\n",
    "    if detail:\n",
    "        return demand_df\n",
    "    else:\n",
    "        demand_df = demand_df.sum(axis=0).loc[area_grid.index] # Aggregate demand in the time window over areas (.loc to remove gps coords and platform)se:\n",
    "        return pd.DataFrame(demand_df, columns=['demand']) # Sum of demand equals to amount of app openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the location of all parked vehicles at any datetime. remove_in_use decides to remove vehicles in transit or keep them and pick their last location\n",
    "def vehicle_locations(timepoint:datetime, rentals:pd.DataFrame=rental, detail:bool=False, remove_in_use:bool=True) -> pd.DataFrame:\n",
    "    filtered_rentals = rentals[rentals['End_Datetime_Local'] <= timepoint].drop('Revenue_Net', axis=1)\n",
    "    filtered_rentals = filtered_rentals.sort_values(by='End_Datetime_Local').drop_duplicates(subset='Vehicle_Number_Plate', keep='last') # Keep the last location\n",
    "    if remove_in_use:\n",
    "        current_trips = rentals[(rentals['Start_Datetime_Local'] <= timepoint) & (rentals['End_Datetime_Local'] > timepoint)] # Cars in use\n",
    "        filtered_rentals = filtered_rentals[~filtered_rentals['Vehicle_Number_Plate'].isin(current_trips['Vehicle_Number_Plate'])] # Filter out cars in use\n",
    "    filtered_rentals = filtered_rentals.loc[:, ~filtered_rentals.columns.str.contains('Start')].drop(columns=['End_Datetime_Local'], axis=1) # Drop unused columns\n",
    "    filtered_rentals.rename(columns={'End_GPS_Latitude': 'GPS_Latitude', 'End_GPS_Longitude': 'GPS_Longitude', 'End_Zone_Name': 'Zone'}, inplace=True)\n",
    "    if detail:\n",
    "        filtered_rentals = pd.get_dummies(filtered_rentals, columns=['Zone'])\n",
    "        filtered_rentals.columns = filtered_rentals.columns.str.replace('^Zone_', '', regex=True) # Remove area_ prefix in columns\n",
    "        return filtered_rentals\n",
    "    else:\n",
    "        all_vehicles = filtered_rentals.columns[filtered_rentals.columns.str.contains('Vehicle_Model')] # Get name of vehicles\n",
    "        filtered_rentals = filtered_rentals.groupby('Zone')[all_vehicles].sum() # Aggregate amount of cars\n",
    "        missing_areas = pd.DataFrame(index=area_centers.index[~area_centers.index.isin(filtered_rentals.index)], columns=filtered_rentals.columns, data=0)\n",
    "        return pd.concat([filtered_rentals, missing_areas]).sort_index() # Add missing areas, sort and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the total revenue in the last time window at any datetime\n",
    "def revenue(timepoint:datetime, window:timedelta=timedelta(hours=1), rentals:pd.DataFrame=rental) -> float:\n",
    "    trips_in_window = rentals[(rentals['Start_Datetime_Local'] >= timepoint-window) & (rentals['End_Datetime_Local'] < timepoint)]\n",
    "    return trips_in_window['Revenue_Net'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(timepoint:datetime, windows:List[timedelta]=[timedelta(hours=1)], coords:bool=False) -> Tuple[Tuple[float], Tuple[pd.DataFrame]]:\n",
    "    df = deepcopy(area_centers)\n",
    "    df = pd.concat([df, vehicle_locations(timepoint=timepoint)], axis=1) # Locations now\n",
    "    dfs = []\n",
    "    revenues = []\n",
    "    for time_window in windows:\n",
    "        locs = vehicle_locations(timepoint=timepoint-time_window, remove_in_use=False) # Locations at beginning of time window\n",
    "        dem = demand(timepoint=timepoint, window=time_window) # Demand in time window\n",
    "        locs.columns = locs.columns + '_' + str(int(time_window.days*24 + time_window.seconds/3600)) + 'h' # Add time window to column name\n",
    "        dem.columns = dem.columns + '_' + str(int(time_window.days*24 + time_window.seconds/3600)) + 'h' # Add time window to column name\n",
    "        df = pd.concat([df, dem, locs], axis=1) # Add demands and locations to final dataframe\n",
    "        revenues.append(revenue(timepoint=timepoint, window=time_window))\n",
    "        if coords:\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            dfs.append(df.iloc[:,3:])\n",
    "    return tuple(revenues), tuple(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r, df = get_data(timepoint=datetime(2020, 6, 12, 12, 0, 0),\n",
    "                 windows=[timedelta(hours=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d94d0ed83f522406a66ef1c16a9f665c01f55c8b7daf66f12e3948e08645e5e1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
