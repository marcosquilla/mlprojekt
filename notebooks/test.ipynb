{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, List, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from pyproj import Geod\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "import folium\n",
    "import folium.plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(True).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\marco\\\\OneDrive\\\\mlprojekt\\\\data\\\\processed\\\\locations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dbff23cdb023>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;34m'data'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'processed'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'locations.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Vehicle_Number_Plate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreorder_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\marco\\\\OneDrive\\\\mlprojekt\\\\data\\\\processed\\\\locations.csv'"
     ]
    }
   ],
   "source": [
    "i=pd.MultiIndex.from_frame(pd.read_csv((Path.cwd().parent/ 'data' / 'processed' / 'locations.csv'), usecols=['Time', 'Vehicle_Number_Plate'], parse_dates=['Time'])).reorder_levels([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv((Path.cwd().parent / 'data' / 'processed' / 'actions.csv'), parse_dates=['Time'])\n",
    "a.index = pd.MultiIndex.from_frame(a.loc[:,['Time', 'Vehicle_Number_Plate']])\n",
    "a.drop(labels=['Time', 'Vehicle_Number_Plate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0780527920256718"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)/len(i)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9552"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12237871"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('2020-02-01 00:56:26', 'BZ20249'),\n",
       "            ('2020-02-01 00:56:26', 'BZ48758'),\n",
       "            ('2020-02-01 00:56:26', 'CL35220'),\n",
       "            ('2020-02-01 00:56:26', 'BZ23117'),\n",
       "            ('2020-02-01 00:56:26', 'CL35222'),\n",
       "            ('2020-02-01 00:56:26', 'CL35213'),\n",
       "            ('2020-02-01 00:56:26', 'BZ23116'),\n",
       "            ('2020-02-01 00:56:26', 'BZ23131'),\n",
       "            ('2020-02-01 00:56:26', 'BZ48760'),\n",
       "            ('2020-02-01 00:56:26', 'CL35182')],\n",
       "           names=['Time', 'Vehicle_Number_Plate'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental = pd.read_csv(Path.cwd().parent / 'data' / 'interim' / 'rental.csv', low_memory=False)\n",
    "openings = pd.read_csv(Path.cwd().parent / 'data' / 'interim' / 'openings.csv')\n",
    "virtual_area_centers = pd.read_csv(Path.cwd().parent / 'data' / 'processed' / 'areas.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area centers based on current areas\n",
    "area_centers = rental.groupby('Start_Zone_Name').mean()[['Start_GPS_Latitude','Start_GPS_Longitude']]\n",
    "area_centers.rename(columns={\n",
    "    'Start_GPS_Latitude': 'GPS_Latitude', \n",
    "    'Start_GPS_Longitude': 'GPS_Longitude'}, inplace=True)\n",
    "area_centers.index.names = ['Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "openings['Created_Datetime_Local'] = pd.to_datetime(openings['Created_Datetime_Local'], format='%Y-%m-%d %H:%M')\n",
    "openings = pd.get_dummies(openings, columns=['Platform'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental['Start_Datetime_Local'] = pd.to_datetime(rental['Start_Datetime_Local'], format='%Y-%m-%d %H:%M')\n",
    "rental['End_Datetime_Local'] = pd.to_datetime(rental['End_Datetime_Local'], format='%Y-%m-%d %H:%M')\n",
    "rental = pd.get_dummies(rental, columns=['Vehicle_Engine_Type'], drop_first=True)\n",
    "rental = pd.get_dummies(rental, columns=['Vehicle_Model'])\n",
    "rental['VZE_ori'] = rental['Virtual_End_Zone_Name']\n",
    "rental = pd.get_dummies(rental, columns=['Virtual_End_Zone_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limits: 2020-02-01 00:56:26 to 2021-05-03 23:59:51\n"
     ]
    }
   ],
   "source": [
    "time_start = max(rental['Start_Datetime_Local'].min(), openings['Created_Datetime_Local'].min())\n",
    "time_end = min(rental['End_Datetime_Local'].max(), openings['Created_Datetime_Local'].max())\n",
    "print('Time limits:', time_start, 'to', time_end)\n",
    "total_time = time_end-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step=timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = rental.columns[rental.columns.str.contains('Vehicle_Model')] # Get names of vehicles\n",
    "timepoints = np.arange(time_start, time_end, time_step).astype(datetime)\n",
    "time_window = timedelta(minutes=15)\n",
    "cars = pd.unique(rental['Vehicle_Number_Plate'])\n",
    "indeces = list(product(timepoints, cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand(idx):\n",
    "    # Auxiliary method for __getitem__. Uses array timepoint as a index. Returns the demand of all areas at some point in time.\n",
    "    dem = openings[(openings['Created_Datetime_Local'] > timepoints[idx]-time_window) &\n",
    "    (openings['Created_Datetime_Local'] <= timepoints[idx])].copy()\n",
    "    if len(dem) == 0:\n",
    "        return pd.Series(data=0, index=np.arange(len(virtual_area_centers)))\n",
    "    else:\n",
    "        dem[virtual_area_centers.index.values] = 0 # Create columns with area names\n",
    "        di = dem.apply(lambda x: coords_to_areas(x), axis=1)\n",
    "        dem[virtual_area_centers.index.values] =  di # Apply function to all openings\n",
    "        return dem.loc[:,virtual_area_centers.index].sum(axis=0) # Aggregate demand in the time window over areas (.loc to remove gps coords and platform). Sum of demand equals to amount of app openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the location of all parked vehicles at any datetime. remove_in_use decides to remove vehicles in transit or keep them and pick their last location\n",
    "def vehicle_locations(idx):\n",
    "    loc = rental[rental['End_Datetime_Local'] <= timepoints[idx]]\n",
    "    loc = loc.drop_duplicates(subset='Vehicle_Number_Plate', keep='last') # Keep the last location\n",
    "    current_trips = rental[(rental['Start_Datetime_Local'] <= timepoints[idx]) & (rental['End_Datetime_Local'] > timepoints[idx])] # Cars in use\n",
    "    loc = loc[~loc['Vehicle_Number_Plate'].isin(current_trips['Vehicle_Number_Plate'])] # Filter out cars in use\n",
    "    #loc = loc.loc[:, ~loc.columns.str.contains('Start')].drop(columns=['End_Datetime_Local'], axis=1) # Drop unused columns\n",
    "    #loc = loc.groupby('Virtual_End_Zone_Name')[vehicles].sum() # Aggregate amount of cars\n",
    "    #missing_areas = pd.DataFrame(index=virtual_area_centers.index[~virtual_area_centers.index.isin(loc.index)], columns=loc.columns, data=0)\n",
    "    #loc = pd.melt(pd.concat([loc, missing_areas]), ignore_index=False) # Add missing areas and unpivot\n",
    "    #loc.index = loc.index.astype('str')+loc.variable # Join zone and vehicle model, necessary to sort\n",
    "    #return torch.tensor(loc.drop(labels='variable', axis=1).sort_index().values).squeeze() # Drop vehicle model (already in index) and sort\n",
    "    loc['Time'] = timepoints[idx]\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = np.append(rental.columns[(rental.columns.str.contains('Plate') | rental.columns.str.contains('Vehicle_Model') | rental.columns.str.contains('Virtual'))].values, 'Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vehicle_locations(0).loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = vehicle_locations(1).loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a.append(b)\n",
    "c.index = pd.MultiIndex.from_frame(c.loc[:,['Time', 'Vehicle_Number_Plate']], names=['Time', 'Vehicle_Number_Plate'])\n",
    "c.drop(labels=['Vehicle_Number_Plate', 'Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(c.loc[timepoints[0], 'BZ20249'])\n",
    "except KeyError:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state(idx):\n",
    "    # Auxiliary method for __getitem__. Joins vehicle locations and demand\n",
    "    dem = demand(idx)\n",
    "    loc = vehicle_locations(idx)\n",
    "    return torch.hstack((torch.tensor(timepoints[idx].month), torch.tensor(timepoints[idx].day), torch.tensor(timepoints[idx].hour), dem, loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state(20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def test(idx):\n",
    "#    # Auxiliary method for __getitem__. Calculates actions\n",
    "#    a = rental[(rental['Servicedrive_YN']==1) &\n",
    "#                    (rental['Start_Datetime_Local'] >= timepoints[idx]-time_window) &\n",
    "#                    (rental['Start_Datetime_Local'] < timepoints[idx])]\n",
    "#    a = a[a['Virtual_Start_Zone_Name'] != a['Virtual_End_Zone_Name']]\n",
    "#    a = a.loc[:, [*vehicles, 'Virtual_Start_Zone_Name', 'Virtual_End_Zone_Name', 'Servicedrive_YN']]\n",
    "#    a = pd.melt(a, id_vars=['Virtual_Start_Zone_Name', 'Virtual_End_Zone_Name'], value_vars=[*vehicles])\n",
    "#    a = a[a.value>0]\n",
    "#    return a\n",
    "#ac = []\n",
    "#for i in tqdm(range(1000)):\n",
    "#    ac.append(len(test(i)))\n",
    "#bins = np.arange(0, 10, 1) # fixed bin size\n",
    "#plt.xlim([0, 10])\n",
    "#plt.hist(ac, bins=bins, density=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = 5\n",
    "n_areas = len(virtual_area_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(idx):\n",
    "    ad = rental[(rental['Servicedrive_YN']==1) &\n",
    "                    (rental['Start_Datetime_Local'] >= timepoints[idx]-time_window) &\n",
    "                    (rental['Start_Datetime_Local'] < timepoints[idx])]\n",
    "    ad = ad[ad['Virtual_Start_Zone_Name'] != ad['VZE_ori']]\n",
    "    #ad = np.reshape(ad.to_numpy(), (-1, ad.shape[1]))\n",
    "    #a = np.zeros((n_actions, ad.shape[1]), dtype=np.int8)\n",
    "    #a[:ad.shape[0]] = ad\n",
    "    #a[ad.shape[0]:, [0, -2*n_areas, -n_areas]] = 1\n",
    "    #return torch.from_numpy(a)\n",
    "    ad['Time'] = timepoints[idx]\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle_Number_Plate</th>\n",
       "      <th>Revenue_Net</th>\n",
       "      <th>Start_Datetime_Local</th>\n",
       "      <th>End_Datetime_Local</th>\n",
       "      <th>Start_GPS_Latitude</th>\n",
       "      <th>Start_GPS_Longitude</th>\n",
       "      <th>End_GPS_Latitude</th>\n",
       "      <th>End_GPS_Longitude</th>\n",
       "      <th>Package_Description</th>\n",
       "      <th>Operation_State_Name_Before</th>\n",
       "      <th>...</th>\n",
       "      <th>Virtual_End_Zone_Name_41</th>\n",
       "      <th>Virtual_End_Zone_Name_42</th>\n",
       "      <th>Virtual_End_Zone_Name_43</th>\n",
       "      <th>Virtual_End_Zone_Name_44</th>\n",
       "      <th>Virtual_End_Zone_Name_45</th>\n",
       "      <th>Virtual_End_Zone_Name_46</th>\n",
       "      <th>Virtual_End_Zone_Name_47</th>\n",
       "      <th>Virtual_End_Zone_Name_48</th>\n",
       "      <th>Virtual_End_Zone_Name_49</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Vehicle_Number_Plate, Revenue_Net, Start_Datetime_Local, End_Datetime_Local, Start_GPS_Latitude, Start_GPS_Longitude, End_GPS_Latitude, End_GPS_Longitude, Package_Description, Operation_State_Name_Before, Operation_State_Name_After, Reservation_YN, Prebooking_YN, Servicedrive_YN, Start_Zone_Name, End_Zone_Name, Virtual_Start_Zone_Name, Vehicle_Engine_Type_ED, Vehicle_Model_ACLASS, Vehicle_Model_BCLASS, Vehicle_Model_BMW_1ER, Vehicle_Model_BMW_I3, Vehicle_Model_BMW_X1, Vehicle_Model_CLA, Vehicle_Model_FIAT_500, Vehicle_Model_MINI_3-TUERER, Vehicle_Model_MINI_5-TUERER, Vehicle_Model_MINI_BEV, Vehicle_Model_TBD, VZE_ori, Virtual_End_Zone_Name_0, Virtual_End_Zone_Name_1, Virtual_End_Zone_Name_2, Virtual_End_Zone_Name_3, Virtual_End_Zone_Name_4, Virtual_End_Zone_Name_5, Virtual_End_Zone_Name_6, Virtual_End_Zone_Name_7, Virtual_End_Zone_Name_8, Virtual_End_Zone_Name_9, Virtual_End_Zone_Name_10, Virtual_End_Zone_Name_11, Virtual_End_Zone_Name_12, Virtual_End_Zone_Name_13, Virtual_End_Zone_Name_14, Virtual_End_Zone_Name_15, Virtual_End_Zone_Name_16, Virtual_End_Zone_Name_17, Virtual_End_Zone_Name_18, Virtual_End_Zone_Name_19, Virtual_End_Zone_Name_20, Virtual_End_Zone_Name_21, Virtual_End_Zone_Name_22, Virtual_End_Zone_Name_23, Virtual_End_Zone_Name_24, Virtual_End_Zone_Name_25, Virtual_End_Zone_Name_26, Virtual_End_Zone_Name_27, Virtual_End_Zone_Name_28, Virtual_End_Zone_Name_29, Virtual_End_Zone_Name_30, Virtual_End_Zone_Name_31, Virtual_End_Zone_Name_32, Virtual_End_Zone_Name_33, Virtual_End_Zone_Name_34, Virtual_End_Zone_Name_35, Virtual_End_Zone_Name_36, Virtual_End_Zone_Name_37, Virtual_End_Zone_Name_38, Virtual_End_Zone_Name_39, Virtual_End_Zone_Name_40, Virtual_End_Zone_Name_41, Virtual_End_Zone_Name_42, Virtual_End_Zone_Name_43, Virtual_End_Zone_Name_44, Virtual_End_Zone_Name_45, Virtual_End_Zone_Name_46, Virtual_End_Zone_Name_47, Virtual_End_Zone_Name_48, Virtual_End_Zone_Name_49, Time]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 81 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions(0)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_act = np.append(rental.columns[(rental.columns.str.contains('Plate') | rental.columns.str.contains('Virtual_End_Zone_Name_'))].values, 'Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.append(actions(206))[cols_act]\n",
    "b.index = pd.MultiIndex.from_frame(b.loc[:,['Time', 'Vehicle_Number_Plate']])\n",
    "b.drop(labels=['Time', 'Vehicle_Number_Plate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces[217360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b.loc[indeces[217360]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue(idx):\n",
    "    # Auxiliary method for __getitem__. Uses array timepoint as a index.\n",
    "    trips_in_window = rental[(rental['Start_Datetime_Local'] >= timepoints[idx]-time_window) & (rental['End_Datetime_Local'] < timepoints[idx])]\n",
    "    return torch.tensor(trips_in_window['Revenue_Net'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "def item(idx):\n",
    "    s = state(idx) # Returns position of cars in timepoint idx and demand between idx-timedelta and idx\n",
    "    a = actions(idx) # Returns end position of cars due to service trips within idx-timedelta (only moved cars)\n",
    "    s1 = state(idx+1) # Returns position of cars in timepoint idx+1 and demand between idx+1-timedelta and idx+1\n",
    "    r = revenue(idx) # Returns total revenue between idx-timedelta and idx\n",
    "    return s, a, s1, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d94d0ed83f522406a66ef1c16a9f665c01f55c8b7daf66f12e3948e08645e5e1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
